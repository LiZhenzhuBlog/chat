<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>李珍珠</title>
    <div class="namemy">

    <h3>by:李珍珠</h3>
    <hr>
	</div>
    
    <style>
      svg.markmap {
        width: 100%;
        height: 90vh;
      }
  .image {
        display: flex; /* 使用Flexbox布局 */
        height: 6vh;

      flex-wrap: wrap;
        justify-content: space-between; /* 自动平均分布元素 */
    }
   .namemy {
        text-align: center;
        height: 2vh;
    }

  .image-container {
    width: 25%;; /* 设置图片容器的宽度 */
    
    position: relative; /* 设置相对定位以容纳图片和描述 */
  }

  .image-container img {
    width: 99%; /* 设置图片的宽度为容器的宽度 */
    height: 100%; /* 设置图片的高度为容器的高度 */
    object-fit: cover; /* 根据需要调整图片的适应方式 */
  }

  .image-container figcaption {
    position: absolute; /* 设置绝对定位以位于图片上方 */
    top: 0; /* 调整描述文本的位置 */
    width: 100%; /* 设置描述文本的宽度与容器一致 */
    background-color: rgba(0, 0, 0, 0.8); /* 调整背景颜色和透明度的值以满足您的需求 */
    color: white; /* 调整字体颜色以满足您的需求 */
    text-align: center;}

    </style>
    <script src="https://cdn.jsdelivr.net/npm/markmap-autoloader@0.14.4"></script>
  </head>
  <body>
    <div class="markmap">
    <script type="text/template">
	---
	markmap:
	  maxWidth: 1000
	  initialExpandLevel: 2
	---

    # 标题：nnU-Net：一种用于基于深度学习的生物医学图像分割的自配置方法
    ## 摘要：
    - 生物医学成像是科学发现的驱动力和医疗护理的核心组成部分，并受到深度学习领域的刺激。虽然语义分割算法在许多应用中实现了图像分析和量化，但相应专门解决方案的设计并不简单，并且高度依赖于数据集属性和硬件条件。我们开发了nnU-Net，一种基于深度学习的分割方法，可以自动配置自身，包括预处理、网络架构、训练和后处理，适用于任何新任务。这个过程中的关键设计选择被建模为一组固定参数、相互依赖的规则和经验决策。在没有手动干预的情况下，nnU-Net在国际生物医学分割竞赛中使用的23个公共数据集上超越了大多数现有方法，包括高度专门化的解决方案。我们将nnU-Net公开提供作为一种开箱即用的工具，使得最先进的分割技术对广大用户可用，无需专业知识和超出标准网络训练的计算资源。

    ## 结果：
    ### 1、总体结果,nnU-Net能够自动适应任何新的数据集
    #### nnU-Net是一种基于深度学习的分割方法，它能够自动配置自身，包括预处理、网络架构、训练和后处理，适用于生物医学领域的任何新任务。图1展示了nnU-Net在各种数据集上生成的示例分割结果。图2展示了nnU-Net如何系统地处理整个分割流程的配置，并提供了最相关设计选择的可视化和描述。nnU-Net的开发基于将领域知识提炼为三个参数组：固定参数、基于规则的参数和经验参数。首先，我们收集所有在数据集之间不需要调整的设计选择（例如将架构模板设置为“类似U-Net”），并优化它们的联合配置，以实现在我们的开发数据集上的稳健泛化。其次，对于尽可能多的剩余决策，我们在“数据集指纹”（包括图像大小、像素间距信息或类别比例等关键属性的标准化数据集表示）和“流程指纹”（我们定义为方法设计过程中所做的全部选择）之间建立明确的依赖关系。这些依赖关系以相互依赖的启发式规则的形式建模，可以在应用时几乎立即执行。举一个这样的规则的例子，批处理大小、块大小和网络拓扑的相互依赖配置基于以下三个原则。
    #### 较大的批大小可以提供更准确的梯度估计，因此是更可取的（在我们的领域通常没有达到的一个甜点），但在实践中，任何大于一个的批大小已经可以得到稳健的训练结果。
    #### 在训练过程中，较大的补丁大小可以增加网络吸收的上下文信息，因此对性能至关重要。
    #### 网络的拓扑结构应该足够深，以确保有效的感受野大小至少与补丁大小一样大，这样上下文信息才不会被丢弃。
    	将这些知识转化为成功的方法设计，得出以下启发式规则：“将补丁大小初始化为中位数图像形状，并在适应网络拓扑的同时逐步减小它（包括网络深度、每个轴上的池化操作的数量和位置、特征图大小和卷积核大小），直到网络可以在至少两个给定GPU内存约束条件下进行训练。” 在在线方法中提供了所有启发式规则的详细描述，并在附注2中提供了用于推导规则的指导原则的编译。其次，我们只在应用过程中根据训练数据经验决定剩余的设计选择，即模型选择和后处理。我们称之为nnU-Net的这种方法的实现，仅在源自Medical Decathlon分割挑战的十个开发数据集上进行了开发。
        nnU-Net应用。将nnU-Net应用于新的数据集时，nnU-Net的自动配置运行时不需要手动干预。因此，除了剩下的少数经验选择需要进行的外，不需要额外的计算成本，只需进行标准网络训练过程。nnU-Net的自动化方法配置从提取数据集指纹开始，然后执行启发式规则。默认情况下，nnU-Net生成三种不同的U-Net15配置：一个二维（2D）U-Net，一个在完整图像分辨率下操作的3D U-Net，以及一个3D U-Net级联，其中第一个U-Net在降采样图像上操作，第二个U-Net在全分辨率上训练以改进前者创建的分割图。经过交叉验证，nnU-Net经验性地选择最佳性能的配置或集合。最后，如果测量到性能提升，nnU-Net经验性地选择“非最大组件抑制”作为后处理步骤。nnU-Net的自动配置和训练过程的输出是完全训练好的模型，可以部署到未知图像上进行预测。我们通过将nnU-Net应用于其他13个数据集来展示nnU-Net中编码的设计选择的泛化能力。
        有关nnU-Net背后的方法论以及其总体设计原则的详细描述分别在“方法”和“补充说明2”中提供。nnU-Net生成的所有数据集的分割流程在“补充说明6”中提供。
    ### 2、nnU-Net是一个处理各种目标结构和图像属性的工具。
    #### 我们通过将nnU-Net应用于11个国际生物医学图像分割挑战，涵盖了23个不同的数据集和53个分割任务，展示了nnU-Net作为一个开箱即用的分割工具的价值（https://cremi.org/）。这些选择包括了各种器官、器官亚结构、肿瘤、病变和细胞结构，以及通过磁共振成像（MRI）、计算机断层扫描（CT）、电子显微镜（EM）和荧光显微镜（FM）获取的2D和3D图像。这些“挑战”是国际竞赛，旨在评估多个算法在标准化环境中的性能。在所有的分割任务中，nnU-Net都是从头开始使用提供的挑战数据进行训练的。从定性上看，我们观察到nnU-Net能够处理数据集属性的巨大差异和目标结构的多样性，即生成的管道配置与人类专家认为合理或明智的设置一致（附注3的补充说明，第1和第2节）。nnU-Net生成的分割结果示例如图1所示。
    ### 3、与其他模型的比较
    #### nnU-Net在各种不同任务中表现优于专门的流水线方法。图3提供了nnU-Net和其他参与竞赛的团队在所有53个分割任务中取得的定量结果概述。尽管nnU-Net是通用方法，但它的表现超过了大多数现有的分割解决方案，即使后者是针对特定任务进行了优化。总体而言，nnU-Net在53个目标结构中有33个取得了最新的技术水平，并且在其余任务中表现接近或与领先的竞赛参与者相当。
    ### 4、 方法配置的细节对性能的影响要大于架构变化。
    #### 为了更深入地了解基于深度学习的生物医学图像分割的当前实践，我们以最近由医学图像计算与计算机辅助干预(MICCAI)学会举办的肾脏和肾脏肿瘤分割(KiTS) 2019挑战为例进行分析。MICCAI学会一直承办至少50%的年度生物医学图像分析挑战。KiTS挑战是MICCAI 2019年规模最大的竞赛，共有100多个参赛者。首先观察到的是，自动机器学习方法在排行榜中明显缺席。只有一个提交（排名100个中的第18个）报告了通过网格搜索选择了“一些超参数”（http://results.kits-challenge.org/miccai2019/manuscripts/peekaboo_2.pdf），而手动的试错优化则是不可否认的现状。值得注意的是，这个观察结果并不仅适用于KiTS，我们不知道在任何生物医学图像分割竞赛中有使用自动机器学习方法的成功提交。图4a提供了KiTS排行榜的总体概述（http://results.kits-challenge.org/miccai2019），进一步揭示了基于深度学习的分割方法设计的当前情况。首先，前15个方法都是基于2016年的(3D) U-Net架构衍生出来的(refs. 15,26)，证实了它对生物医学图像分割领域的影响。其次，使用相同类型的网络的贡献在整个排行榜上表现出分散的性能。第三，在检查前15个方法时，常用的架构修改（例如残差连接27,28，稠密连接29,30，注意力机制31或空洞卷积32,33）对于在KiTS任务上获得良好性能并不是必要条件。
    图4b强调了找到良好的方法配置的重要性。它展示了使用与挑战获胜贡献相同的变体体系结构，即具有残差连接的3D U-Net，进行的算法分析。虽然其中一种方法赢得了挑战，但其他基于同一原则的贡献涵盖了整个评估分数和排名范围。关键配置参数是从各自的流水线指纹中选择的，这说明每个团队在方法配置过程中所做的相互依赖的设计选择。参赛者提交的差异巨大的配置表明，为生物医学图像分割配置深度学习方法所隐含的高维优化问题的复杂性。
    nnU-Net在KiTS数据集上进行的实验证明了方法配置相对于架构变化的相对重要性，在开放排行榜上取得了新的最佳成绩（nnU-Net是在原始挑战结束后提交到排行榜的，因此不是原始排行榜分析的一部分。在图4中分析的方法也列在开放排行榜上）。这一观察结果与我们在其他22个数据集上的结果一致（图3）。
    ### 5、不同的数据集需要不同的流程配置。
    #### 我们提取了23个生物医学分割数据集的数据指纹。如图5所示，这展示了生物医学成像中异常的数据集多样性，并揭示了缺乏开箱即用的分割算法的根本原因：方法配置的复杂性被放大，因为适当的流程设置直接或间接地取决于数据指纹，在可能的复杂关系下。因此，对于一个数据集（比如KiTS，参见上文）被确定为最佳的流程设置可能不适用于其他数据集，导致需要为每个单独的数据集重新优化。nnU-Net通过识别稳健的设计决策并明确建模关键的相互依赖关系（图2）来应对这个挑战。
    ### 6、多任务能够支持稳健的设计决策。
    #### nnU-Net的自动方法配置可以被研究人员利用来开发新的分割方法。新颖的想法可以很容易地集成到nnU-Net中，并在多个数据集上进行测试，而无需为每个数据集手动重新配置整个流程。为了展示这种方法的优势，并支持nnU-Net的一些核心设计选择，我们系统地测试了常见的流程变体的性能，通过系统地修改nnU-Net的一些固定参数。我们在十个不同的数据集上评估了以下变体，并与我们默认的nnU-Net配置进行了比较，该配置在这些实验中作为基准（图6）。数据集之间排名的变动性表明，单一的设计选择会根据数据集而影响分割性能。结果清楚地表明，在基于不足数量的数据集进行评估时，需要谨慎得出方法论结论。虽然九个变体中有五个在至少一个数据集中排名第一，但它们在十个任务中都没有一致的改进表现。原始的nnU-Net配置展示了最好的泛化性能，并在汇总了所有数据集的结果中排名第一。
    

    ## 图片：
    ###  图1 nnU-Net可以处理各种不同的数据集和目标图像属性。
    ####所有示例均来自应用nnU-Net的不同国际分割挑战的测试集。每个数据集的目标结构在二维平面上映射到原始数据上（左侧），并在三维空间中显示与原始数据的体渲染图像（右侧）。所有可视化结果均使用MITK Workbench35创建。a、CT图像（数据集（D）18）14中的心脏（绿色）、主动脉（红色）、气管（蓝色）和食管（黄色）。b、FM（D22）36,37中的A549肺癌细胞（紫色）。c、CT图像（D6）14中的肺结节（黄色）。d、T1相MRI（D16）20中的肝脏（黄色）、脾脏（橙色）、左肾和右肾（蓝色和绿色）。e、EM扫描（D19）中的突触间隙（绿色）（https://cremi.org/）。f、MRI（T1、T1对比剂、T2、FLAIR）（D1）14中的水肿（黄色）、增强肿瘤（紫色）、坏死（绿色）。g、CT图像（D17）21中的肾脏（黄色）和肾肿瘤（绿色）。h、CT图像（D11）16中的十三个腹部器官。i、CT（D8）14中的肝脏血管（黄色）和肝肿瘤（绿色）。j、MRI（D2）14中的左心室（黄色）。k、cine MRI（D13）6中的右心室（黄色）、左心室腔（蓝色）和左心室心肌（绿色）。l、FM（D21）39中的HL60细胞核（实例分割，每个实例一种颜色）。
    ### 图2  基于深度学习的生物医学图像分割的自动方法配置。
    ####给定一个新的分割任务，数据集的属性以“数据集指纹”（粉色）的形式提取出来。一组启发式规则模型参数之间的相互依赖关系（表示为细箭头），并在这个指纹上操作，推断出数据相关的“基于规则的参数”（绿色）的流程。这些参数由预定义的“固定参数”（蓝色）补充，不需要进行调整。使用五折交叉验证训练最多三个配置。最后，nnU-Net自动选择这些模型的最佳集合，并确定是否需要后处理（“经验参数”，黄色）。底部的表格显示了所有配置参数的显式值以及总结的规则公式。Res.代表分辨率。
        - 设计选择所需输入自动化（固定的、基于规则的或经验性的）配置，通过提炼专家知识来得到（更多细节请参见在线方法）
            学习率 - 多项式学习率调度（初始值为0.01）
            损失函数 - Dice和交叉熵
            架构模板 - 编码器-解码器结构，带有跳跃连接（类似于U-Net），实例归一化，泄漏ReLU，深度监督（拓扑自适应于推断参数）
            优化器 - 带有Nesterov动量的SGD（µ = 0.99）
            数据增强 -旋转，缩放，高斯噪声，高斯模糊，亮度，对比度，低分辨率模拟，伽马校正和镜像
            训练过程 - 1,000个epoch × 250个minibatches，前景过采样
            推理过程 - 滑动窗口，半补丁大小重叠
        - 粉色 密度归一化模态，强度分布如果是CT，使用全局数据集百分位数裁剪和z得分，使用全局前景均值和标准差。否则，使用每个图像的均值和标准差进行z得分。
        图像重采样策略  间距分布 如果是各向异性，使用三阶样条插值进行平面内插值，使用最近邻进行平面外插值。否则，使用三阶样条插值。
            注释重采样策略 间距分布 转换为one-hot编码→  如果是各向异性，使用线性插值进行平面内插值，使用最近邻进行平面外插值。否则线性插值
        图像目标间距 间距分布 如果是各向异性，最低分辨率轴的第十百分位数，其他轴的中位数。否则，每个轴的中位间距。
            （根据训练样例中的间距计算）
        网络拓扑，补丁大小，批量大小 中位数重采样形状，目标间距，GPU内存限制将补丁大小初始化为中位数图像形状，并在适应网络拓扑的同时逐步减小补丁大小，直到网络可以在至少2个GPU内存约束下进行训练。详见在线方法。
        3D U-Net级联的触发条件  中位数重采样图像大小，补丁大小 
            是的，如果3D全分辨率U-Net的补丁大小小于中位数重采样图像形状的12.5%。
            低分辨率3D U-Net的配置 低分辨率目标间距或图像形状，GPU内存限制 通过迭代增加目标间距，重新配置补丁大小、网络拓扑和批量大小（如上所述），直到配置的补丁大小覆盖中位数图像形状的25%。详见在线方法。
        - 后处理配置
            使用完整的训练数据和标注 将所有前景类别视为一个整体；是否通过除最大组件抑制来提高交叉验证性能？
            是的，应用；对各个类别重复操作
            不，不应用；对各个前景类别重复操作
            集成选择
            使用完整的训练数据和标注
            从2D U-Net、3D U-Net或3D级联中选择最佳模型（或两者组合），根据交叉验证性能选择最佳模型。
    ### 图3 nnU-Net优于大多数专业的深度学习流水线。
    ####nnU-Net参与的所有国际挑战的定量结果。对于每个分割任务，nnU-Net取得的结果用红色标出；竞争团队用蓝色显示。对于每个分割任务，nnU-Net的排名以及竞争算法的总数显示在每个图的右下角。请注意，对于CHAOS挑战（D16），由于在补充说明6的第9节中概述的原因，我们只参与了五个子任务中的两个。细胞跟踪挑战排行榜（D20-D23）最后于2020年7月30日访问；所有其余排行榜最后于2019年12月12日访问。SIM，模拟
    ### 图4 KiTS 2019排行榜条目的流水线指纹。
    ####a. 通过架构变化对排行榜条目进行粗略分类。所有前15名的贡献都是具有跳跃连接、3D卷积和输出步幅1的编码器-解码器架构（“3D U-Net-like”，紫色）。b. 从所有非级联的3D U-Net-like架构的流水线指纹中选择的更详细的关键参数（以z-score标准化的尺度显示）。缩写词，CE，交叉熵损失函数；Dice，软Dice损失函数；WBCE，加权二进制CE。有关KiTS 2019挑战的更多信息，请访问http://results.kits-challenge.org/。
    ### 图5 不同挑战数据集的数据指纹。
    ####数据指纹显示了在nnU-Net实验中使用的23个数据集的关键属性（以标准差归一化显示，范围为均值附近的一个标准差），详细的数据集描述请参见附注1。
    ### 图6 跨多个任务评估设计决策。
    ####a-j，在医学分割十项竞赛的十个数据集上评估模型变体：应用两种替代损失函数（交叉熵和TopK1040），在编码器中引入残差连接，使用每个分辨率三个而不是两个卷积（导致更深的网络架构），两种优化器的修改（减小的动量项和替代优化器（Adam）），批归一化代替实例归一化以及省略数据增强（有关其他设计选择的消融实验请参见附注8）。通过将五折交叉验证的验证划分聚合为一个大的验证集来估计每个数据集的排名稳定性。通过自助法（有放回地抽样）生成了一千个虚拟验证集。在每个虚拟验证集上对算法进行排名，得到一个排名的分布，如challengeR工具所建议的。k，对数据集的排名聚合揭示了哪些设计决策具有鲁棒的泛化能力。


    ## 结论：
    ### 总结一下，nnU-Net在各种语义分割挑战中树立了新的技术标杆，并展现出强大的泛化特性，既不需要专业知识，也不需要超出标准网络训练的计算资源。正如Litjens等人所指出并在本文中得到定量证实的那样，生物医学成像中的方法配置过去被认为是一种"高度经验性的实践"，"没有明确的配方可供给出"（参考文献10）。基于本研究提出的方法，nnU-Net能够自动化这种常常不够系统化和繁琐的过程，从而减轻这种负担。我们建议将nnU-Net作为一个开箱即用的工具来进行最先进的分割，作为一个标准化的、与数据集无关的基准来进行比较，并作为一个无需手动努力即可进行大规模创新思想评估的框架。


    ## 方法：
    ### 数据集指纹 
    #### 作为第一步处理，nnU-Net将提供的训练案例裁剪到非零区域。虽然这在我们的实验中对大多数数据集没有影响，但它显著减小了脑部数据集（如D1（脑肿瘤）和D15（多发性硬化症病变））的图像大小，从而提高了计算效率。基于裁剪后的训练数据，nnU-Net创建了一个数据集指纹，捕捉到所有相关的参数和属性：裁剪前后的图像大小（即每个空间维度的体素数量），图像间距（即体素的物理大小），模态（从元数据中读取）和所有图像的类别数，以及训练案例的总数。此外，指纹还包括前景区域（即属于任何类别标签的体素）中强度值的均值和标准差，以及0.5和99.5百分位数，这些统计是在所有训练案例上计算的。
    ### 管道指纹 
    #### nnU-Net通过生成一个包含所有相关信息的所谓管道指纹来自动设计生物医学图像分割的深度学习方法。重要的是，nnU-Net将设计选择减少到非常基本的选择，并使用一组启发式规则自动推断这些选择。这些规则凝结了领域知识，并且操作在上述描述的数据指纹和项目特定的硬件约束上。这些基于规则的参数由固定参数和经验参数补充，固定参数是与数据无关的，而经验参数在训练过程中进行优化。
    ### 固定参数
    #### 架构模板。
    ##### nnU-Net配置的所有U-Net架构都源自同一个模板。该模板紧随原始的U-Net15及其3D对应物26。根据我们的假设，即一个良好配置的普通U-Net仍然很难超越，我们的U-Net配置中没有使用最近提出的架构变体，如残差连接28,41，密集连接29,30，注意力机制31，压缩与激发网络46或扩张卷积32。对原始架构进行了细微的更改。为了实现大尺寸的补丁，nnU-Net中网络的批量大小较小。实际上，大多数3D U-Net配置都是以仅两个批次大小进行训练的（附注5中的图SN5.1a）。批量归一化43通常用于加快或稳定训练，但在小批量大小下效果不佳47,48。因此，我们对所有U-Net模型使用了实例归一化44。此外，我们用泄漏的ReLU49（负斜率为0.01）替换了ReLU。网络使用深度监督进行训练；除了最低分辨率之外，附加的辅助损失被添加到解码器中，允许梯度更深入地注入到网络中，并促进网络中所有层的训练。所有U-Net在编码器和解码器中都采用每个分辨率步骤两个块的非常常见的配置，每个块由卷积、实例归一化和泄漏的ReLU非线性组成。下采样采用步长卷积实现（基于表示瓶颈50的动机），上采样采用转置卷积实现。为了在性能和内存消耗之间取得平衡，初始特征映射的数量设置为32，并且每个下采样（上采样）操作时加倍（减半）。为了限制最终的模型大小，特征映射数量分别额外限制为320和512。
    #### 训练计划
    ##### 基于经验，并在运行时间和奖励之间进行权衡，所有网络都经过1000个epochs的训练，其中一个epoch被定义为对250个mini-batches的迭代。使用带有Nesterov动量（µ=0.99）和初始学习率为0.01的随机梯度下降来学习网络权重。学习率在训练过程中按照“poly”学习率策略进行衰减，公式为(1−epoch/epochmax)0.9。损失函数是交叉熵和Dice损失的总和。对于每个深度监督输出，使用相应的下采样的ground truth分割掩码进行损失计算。训练目标是所有分辨率处的损失（L）的加权和，L=w1×L1+w2×L2+…其中权重（w）在每个分辨率降低时减半，即w2=½×w1，w3=¼×w1，依此类推，并且归一化为总和为1。小批量样本是从随机选择的训练案例中选择的。通过过采样来确保对类别不平衡的鲁棒处理；66.7%的样本来自于所选训练案例中的随机位置，而33.3%的patch则保证包含所选训练样本中存在的前景类别之一（随机选择）。前景patch的数量取整，并强制最小为1（批量大小为两个，其中一个是随机的，一个是前景patch）。在训练过程中，实时应用各种数据增强技术：旋转、缩放、高斯噪声、高斯模糊、亮度、对比度、低分辨率模拟、伽马校正和镜像。详细信息请参见补充说明4。
    #### 推理
    ##### 图像使用滑动窗口方法进行预测，窗口大小与训练中使用的补丁大小相同。相邻的预测重叠了一个补丁大小的一半。分割的准确性朝窗口边缘降低。为了抑制拼接伪影并减少靠近边界位置的影响，应用了高斯重要性加权，增加了softmax合中心体素的权重。测试时通过沿所有轴镜像增强应用。
    ### 基于规则的参数
    #### 强度归一化
    ##### nnU-Net支持两种不同的图像强度归一化方案。除了CT图像外，所有模态的默认设置是z-score标准化。对于这个选项，在训练和推理过程中，每个图像都是独立进行标准化的，首先减去其均值，然后除以其标准差。如果裁剪导致平均尺寸减小了25%或更多，将创建一个中心非零体素的掩膜，并仅在该掩膜内进行归一化，忽略周围的零体素。对于CT图像，nnU-Net采用了不同的方案，因为强度值是定量的，并反映了组织的物理特性。因此，通过使用适用于所有图像的全局归一化方案，可以保留这些信息。为此，nnU-Net使用前景体素的0.5和99.5百分位数进行裁剪，以及全局前景均值和标准差进行所有图像的归一化。
    #### 重采样
    ##### 在某些数据集中，特别是在医学领域，体素间距（表示体素的物理空间）是不均匀的。卷积神经网络在体素网格上操作，并忽略了这些信息。为了应对这种不均匀性，nnU-Net将所有图像重新采样为相同的目标间距（见下文），采用三阶样条插值、线性插值或最近邻插值。图像数据的默认设置是三阶样条插值。对于异性图像（最大轴间距÷最小轴间距>3），在平面内进行三阶样条插值，而在平面外进行最近邻插值。在异性情况下将平面外轴与其他轴区别对待，可以抑制重采样伪影，因为切片之间的大的轮廓变化更为常见。分割图像通过将其转换为one-hot编码来进行重采样。然后，每个通道使用线性插值进行插值，通过argmax操作获取分割掩膜。同样，在低分辨率轴上使用“最近邻”进行插值处理异性情况。
    #### 目标像素间距
    ##### 选择的目标间距是一个关键参数。较大的间距会导致图像变小，从而丢失细节，而较小的间距会导致图像变大，阻止网络积累足够的上下文信息，因为给定的图形处理单元（GPU）内存预算限制了补丁大小。尽管这种权衡在一定程度上通过3D U-Net级联（见下文）得到解决，但仍需要合理的低分辨率和全分辨率的目标间距。对于3D全分辨率U-Net，nnU-Net使用独立计算每个轴的训练样例中间间距的中值作为默认目标间距。对于各向异性数据集，这个默认值可能导致严重的插值伪影或由于分辨率在训练数据中的巨大差异而导致信息的大量丢失。因此，如果体素和间距的各向异性（即最小间距轴与最大间距轴的比率）都大于三，则选择最低分辨率轴的目标间距为训练样例中间间距的百分之十分位数。对于2D U-Net，nnU-Net通常在分辨率最高的两个轴上操作。如果三个轴都是各向同性的，则使用后两个轴进行切片提取。目标间距是训练样例中间间距的中值（分别计算每个轴）。对于基于切片的处理，不需要沿着平面轴进行重采样。
    #### 网络拓扑、块大小和批大小的调整。
    ##### 找到合适的U-Net架构配置对于良好的分割性能至关重要。nnU-Net在预定义的GPU内存预算范围内优先考虑较大的块大小。较大的块大小可以聚合更多的上下文信息，通常可以提高分割性能。然而，这也会导致批大小减小，从而在反向传播过程中产生更多的梯度噪声。为了提高训练的稳定性，我们要求最小批大小为2，并选择了较大的动量项用于网络训练（固定参数）。在适应过程中还考虑了图像间距：在3D U-Net中，可以配置下采样操作仅在特定轴上操作，卷积核也可以配置仅在某些图像平面上操作（伪2D）。所有U-Net配置的网络拓扑是根据重采样后的中位图像大小以及重采样的目标间距选择的。适应过程的流程图在附注5的图SN5.1中呈现。在下面的文本中，对架构模板的适应过程进行了更详细的描述，这是计算上廉价的。由于GPU内存消耗估计是基于特征图的大小，因此执行适应过程不需要GPU。
    #### 初始化
    #####在重采样后，补丁大小被初始化为中位数图像形状。如果补丁大小不能被2整除（对于每个轴来说），其中nd是下采样操作的数量，将相应地进行填充。
    #### 架构拓扑
    ##### 根据补丁大小和体素间距确定每个轴上的下采样操作数量来配置架构。下采样操作将持续进行，直到进一步下采样会将特征图大小减小到少于四个体素，或者特征图间距变得非均匀。下采样策略由体素间距决定；高分辨率轴会单独进行下采样，直到其分辨率接近低分辨率轴的两倍。随后，所有轴同时进行下采样。对于每个轴，一旦触发了相应的特征图约束，就会单独终止下采样。卷积的默认核大小为3×3×3和3×3，分别用于3D U-Net和2D U-Net。如果轴之间存在初始分辨率差异（定义为间距比大于两倍），则用于平面外轴的核大小将设置为1，直到分辨率在两倍范围内。请注意，卷积核大小在所有轴上保持为3。
    #### 适应GPU内存预算
    ##### 在配置过程中，最大可能的补丁大小受限于GPU内存的量。由于补丁大小在重新采样后初始化为中位图像形状，对于大多数数据集来说，初始大小对于GPU来说太大了，无法容纳。nnU-Net根据网络中特征图的大小估计给定架构的内存消耗，将其与已知内存消耗的参考值进行比较。然后，在迭代过程中逐步减小补丁大小，同时相应地更新架构配置，直到达到所需的预算为止（参见补充说明5中的图SN5.1）。补丁大小的减小总是相对于数据的中位图像形状中的最大轴进行的。每一步中，该轴的减小量为2的nd次方个体素，其中nd是降采样操作的数量。
    #### 批量大小
    ##### 作为最后一步，配置批量大小。如果进行了修剪块大小的操作，则将批量大小设置为2。否则，将使用剩余的GPU内存空间来增加批量大小，直到GPU被充分利用。为了防止过拟合，批量大小被限制在不超过训练样本中所有体素的总数的5%的范围内。附注3的第1和第2节中提供了生成的U-Net架构的示例。
    #### 3D U-Net级联的配置 
    ##### 在降采样数据上运行分割模型会增加修剪块相对于图像的大小，从而使网络能够积累更多的上下文信息。这样做的代价是生成的分割结果的细节减少，并且如果分割目标非常小或具有纹理特征，可能还会导致错误。在假设具有无限GPU内存的情况下，通常会更喜欢使用覆盖整个图像的修剪块尺寸以全分辨率训练模型。3D U-Net级联通过先在降采样图像上运行3D U-Net，然后训练第二个全分辨率的3D U-Net来优化前者的分割图。通过这种方式，“全局”的低分辨率网络使用最大的上下文信息生成其分割输出，然后将其作为额外的输入通道来指导第二个“局部”U-Net。级联仅在3D全分辨率U-Net的修剪块大小覆盖中位图像形状的12.5％以下的数据集上触发。如果是这种情况，则会联合迭代地配置降采样数据的目标间距和相关的3D低分辨率U-Net架构。目标间距初始化为全分辨率数据的目标间距。为了使修剪块尺寸覆盖输入图像的大部分，目标间距逐步增加1％，并在每个步骤中相应地更新架构配置，直到所得网络拓扑的修剪块尺寸超过当前中位图像形状的25％。如果当前间距是各向异性的（最低和最高分辨率轴之间的差异是2倍），只增加更高分辨率轴的间距。级联的第二个3D U-Net的配置与独立的3D U-Net的配置相同，其配置过程如上所述（除了将第一个U-Net的上采样分割图与其输入连接）。附注5的图SN5.1b提供了此优化过程的概述。
    ### 经验参数
    #### 集成和选择U-Net配置
    ##### nnU-Net会根据在训练数据上通过交叉验证计算得到的平均前景Dice系数来自动确定推理时使用的（集成的）配置。所选模型可以是单个U-Net（2D、3D全分辨率、3D低分辨率或级联的全分辨率U-Net），也可以是任意两个配置的集成。模型通过平均Softmax概率进行集成。
    ### 后处理
    #### 基于连通组件的后处理在医学图像分割中常被使用18,25。特别是在器官图像分割中，通过移除除最大连通组件外的所有组件，通常可以帮助消除伪阳性的检测。nnU-Net遵循这一假设，自动对抑制较小组件对交叉验证结果的影响进行基准测试。首先，所有前景类别被视为一个组件。如果除最大区域外的所有区域的抑制改善了平均前景Dice系数，并且没有降低任何类别的Dice系数，那么这个过程将被选择为第一个后处理步骤。最后，nnU-Net基于这一步骤的结果，并决定是否对各个类别执行相同的过程。
    ### 实现细节 
    #### nnU-Net使用Python 3.8.5实现，使用PyTorch框架1.6.0（参考文献52）。数据增强使用Batchgenerators 0.21（参考文献53）。还使用了其他Python库，包括tqdm 4.48.2，dicom2nifti 2.2.10，scikit-image 0.17.2，MedPy 0.4.0，SciPy 1.5.2，batchgenerators 0.21，NumPy 1.19.1，scikit-learn 0.23.2，SimpleITK 1.2.4和pandas 1.1.1。nnU-Net的源代码可在GitHub上获得（https://github.com/MIC-DKFZ/nnUNet）。希望使用nnU-Net作为标准化基准或使用预训练模型进行推理的用户可以通过PyPI安装nnU-Net。有关如何使用nnU-Net的完整描述以及最新版本和依赖项，请参阅GitHub页面上的在线文档。报告摘要。有关研究设计的进一步信息，请参阅与本文相关的Nature Research报告摘要。
    ### 数据
    #### Data availability  All 23 datasets used in this study are publicly available and can be accessed via their respective challenge websites as follows. D1–D10 Medical Segmentation 
            Decathlon, http://medicaldecathlon.com/; D11 Beyond the Cranial Vault (BCV)-Abdomen, https://www.synapse.org/#!Synapse:syn3193805/wiki/; D12 PROMISE12, https://promise12.grand-challenge.org/; D13 ACDC, https://acdc.creatis.insa-lyon.fr/; D14 LiTS, https://competitions.codalab.org/competitions/17094; D15 MSLes, https://smart-stats-tools.org/lesion-challenge; D16 CHAOS, https://chaos.grand-challenge.org/; D17 KiTS, competitions/21145; D19 CREMI, https://cremi.org/; D20–D23 Cell Tracking Challenge, http://celltrackingchallenge.net/
    ### 代码
    #### Code availability The nnU-Net repository is available as Supplementary Software. Updated versions can be found at https://github.com/mic-dkfz/nnunet. Pretrained models for all datasets used in this study are available for download at https://zenodo.org/record/3734294.



    ## 讨论：
    ### 我们提出了一种名为nnU-Net的基于深度学习的分割方法。
    ####它能够自动配置预处理、网络结构、训练和后处理等各个环节，适用于生物医学领域的任何新任务。在评估的大多数任务中，nnU-Net取得了全新的最佳表现，超越了所有相关的专门处理流程。nnU-Net的强大性能不是通过新的网络结构、损失函数或训练方案来实现的（因此被称为nnU-Net，即“没有新网络”），而是通过系统化复杂的手动方法配置过程来实现的，以前要么通过繁琐的手动调整，要么通过纯经验方法来解决，具有实际局限性。我们假设nnU-Net之所以具有最先进的性能，是因为它从大量的图像数据中汲取了知识。
    nnU-Net是一种新的分割工具，可以直接应用于各种生物医学图像数据集，而无需任何用户干预。通过将数据集的特征转化为强大的归纳偏差，nnU-Net能够在新数据集上具备超越单一数据集配置模型的泛化能力。此外，通过将领域知识压缩为一组固定的基于规则和经验的参数，我们提供了一种新的自动方法配置路径，该路径在计算上可行，并且涵盖了整个分割流程，包括网络架构的重要拓扑参数。因此，nnU-Net非常适合那些需要使用语义分割方法但没有专业知识、时间、数据或计算资源来调整现有解决方案的用户。
    ### 我们对KiTS排行榜的分析揭示了生物医学图像分割中手动和不够系统的方法配置现状，并对该领域的当前研究提出了一些重要的暗示。
    ####例如，我们观察到使用相同类型网络的贡献在整个排行榜上表现分散（图4）。这一观察结果与Litjens等人的研究一致，他们在他们的综述中发现“许多研究人员使用完全相同的架构”，但结果却各不相同（参考文献10）。为什么基于文献中提出的架构扩展的性能改进可能无法应用于该领域中的所有数据集，可能有几个原因。首先，生物医学领域数据集的多样性需要专门的方法配置（图5）。因此，对新数据集的方法配置质量可能会掩盖对评估的架构修改效果的影响。这一解释与Litjens等人的观察结果一致，他们得出结论“确切的架构并不是获得良好解决方案的最重要因素”（参考文献10），并且得到nnU-Net的支持，nnU-Net基于强大的方法配置与简单的U-Net架构实现了最先进的结果。其次，在当前的研究实践中，评估很少在两个以上的数据集上进行，即使进行评估，数据集也很大程度上是相似的。重叠属性（如腹部CT扫描）的存在使得在我们的多数据集研究中（图6所示），这种评估方法不适用于得出一般的方法论结论。我们将缺乏足够广泛的评估与手动调整提出的方法以及现有流程（即基准线）适应各个数据集所需的大量工作联系起来。至关重要的是，这个繁琐的过程也可能导致基准线配置不够优化，从而在文献中带来潜在的偏见。nnU-Net能够减轻当前研究中的这些瓶颈。一方面，nnU-Net代表了一种新的方法，不需要手动的任务特定调整，因此可以在任何新的分割任务中作为强大且标准化的基准线。另一方面，nnU-Net可以作为一个可扩展的实验框架，帮助增加在该领域进行评估的数据集数量，研究人员可以轻松地实现方法论的修改。
    ### 尽管nnU-Net在新的数据集上展示了稳健的高质量配置能力，但任务特定的经验优化可能有潜力进一步提高分割性能。
    ####然而，正如介绍中所阐述的，当前经验AutoML方法的实际限制阻碍了其在生物医学图像分割中的应用。另一个限制是与数据驱动优化（“黑盒算法”（参考文献12））相比，缺乏透明度，而nnU-Net由于基于指导原则，每个设计决策都可以追溯到某些数据集属性或有限的经验实验。展望未来，我们认为我们的工作是经验AutoML研究的补充；nnU-Net可以作为整体自动化的基础，可以通过经验优化选择的设计决策（如数据增强或网络架构）来增强。
    ### 尽管nnU-Net在53个不同的任务中表现出色，但仍有一些分割任务可能不适合nnU-Net的自动适应能力。
    ####例如，nnU-Net的开发主要关注Dice系数作为性能评估指标。然而，某些任务可能需要高度领域特定的目标指标进行评估，这可能会影响方法的设计。此外，可能存在未考虑的数据集属性，这可能导致分割性能不佳。一个例子是CREMI挑战赛的突触裂隙分割任务。虽然nnU-Net的性能非常有竞争力（在39个参赛队伍中排名第6），但为了超越最先进的性能，可能需要手动调整损失函数，并进行EM特定的预处理34。原则上，处理nnU-Net尚未覆盖到的情况有两种方法。对于可能经常出现的情况，nnU-Net的启发式规则是非常有用的。对于高度领域特定的情况，nnU-Net应该被视为必要修改的良好起点。



    ## 简介：
    ### 语义分割将原始的生物医学图像数据转化为有意义的、具有空间结构的信息，因此在科学发现中起着重要作用。
    ####同时，语义分割是许多临床应用的重要组成部分，包括人工智能在诊断支持系统、治疗计划支持、术中辅助和肿瘤生长监测等方面的应用。自动分割方法引起了高度的关注，在生物医学领域的国际图像分析竞赛中占据了70%的比例，这反映出对自动分割方法的广泛研究。
    ### 尽管基于深度学习的分割方法取得了最近的成功，但它们对最终用户特定图像分析问题的适用性通常有限。
    ####方法的任务特定设计和配置需要高水平的专业知识和经验，小错误会导致性能大幅下降。特别是在三维生物医学成像中，数据集属性（如成像模态、图像大小、（各向异性）体素间距和类别比例）变化巨大，这个过程可能会很麻烦，而且成功的配置很少能适用于其他数据集。从精确的网络架构到训练计划和数据增强或后处理方法，调整和训练神经网络涉及许多专家决策。每个相互依赖的子组件都由关键参数（如学习率、批量大小或类别采样策略）控制。整体设置中的另一个复杂性层面是训练和推理可用的硬件。在这个高维空间中，纯经验优化相互依赖的设计选择，如自动机器学习（AutoML）领域中先前的研究所建议的，会大幅增加所需的训练案例和计算资源，通常只涵盖分割流程的一小部分（如架构或数据增强），剩余的配置工作留给实验者。此外，将AutoML应用于新数据集需要一组特定的要求。例如，在考虑构建一个合理的问题特定搜索空间时，需要专家的选择。正如我们在国际生物医学分割挑战中的分析结果所示，这些实际限制通常使用户在方法设计过程中只能进行手动和迭代的试错过程，这主要是由个人经验驱动的，文档记录很少，而且通常导致次优的分割流程。
    ### 在这项工作中，我们概述了在生物医学分割中主要由专家驱动的方法配置与主要由数据驱动的自动机器学习方法之间的一条新路径。
    ####具体而言，我们在此定义了一个后续步骤，该步骤在任务不可知的级别上系统化了配置过程，并在给定新任务时大大减少了经验设计选择的搜索空间。1. 收集不需要在数据集之间进行调整的设计决策，并确定一个稳健的通用配置（"固定参数"）。2. 对于尽可能多的剩余决策，以启发式规则的形式明确指定特定数据集属性（"数据集指纹"）与设计选择（"流程指纹"）之间的依赖关系，以便在应用中实现几乎即时的适应性（"基于规则的参数"）。3. 仅从数据中经验性地学习剩余的决策（"经验参数"）。
    ### 我们在由医学分割Decathlon提供的十个数据集上开发和验证了这个方法。结果得到的分割方法被称为nnU-Net，能够对任意新的数据集进行自动配置。
    ####与现有的研究方法相比，nnU-Net是综合的，即其自动配置涵盖了整个分割流程（包括网络架构的关键拓扑参数），无需任何手动决策。此外，nnU-Net的自动配置速度快，只需执行简单的规则和少数经验性选择，几乎不需要超出标准模型训练的计算资源。最后，nnU-Net具有数据效率；基于大量多样的数据池的设计选择编码作为应用于训练数据有限的数据集的强大归纳偏差。nnU-Net的自动配置的广泛适用性在额外的13个数据集上得到了验证。总共，我们报告了53个分割任务的结果，涵盖了前所未有的多样性目标结构、图像类型和图像属性。作为一个开源工具，nnU-Net可以直接训练，生成最先进的分割结果。

    
    ## GPT检索的未知知识
    ### 在深度学习中，batch size、patch size和network topology是三个重要的概念。
    #### Batch size（批大小）：在训练深度神经网络时，数据通常会被划分为小批量进行处理。Batch size指的是每次迭代训练时所使用的样本数量。较大的batch size可以加快训练速度，但同时也会占用更多的内存。较小的batch size可能会增加训练的噪声，但可以更好地利用GPU的并行性。
    #### Patch size（补丁大小）：在图像处理任务中，尤其是图像分割任务中，通常将图像分割成较小的块或补丁进行处理。Patch size指的是这些补丁的大小。较小的patch size可以捕捉到更多的细节信息，但可能会导致较高的计算复杂度。较大的patch size可以提取更全局的特征，但可能会丧失一些细节。
    #### Network topology（网络拓扑）：在深度学习中，网络拓扑指的是神经网络的结构和连接方式。它决定了网络中神经元的排列方式以及它们之间的连接方式。不同的网络拓扑可以适用于不同的任务和数据集。常见的网络拓扑包括全连接网络、卷积神经网络（CNN）、循环神经网络（RNN）等。
    ### One-hot编码
    #### 是将离散特征转化为二进制向量的一种编码方式。它的基本思想是将每个取值转化为一个长度等于特征取值个数的向量，其中只有一个元素为1，其余元素为0。这个元素的位置表示该特征取值的索引。通过这种编码方式，可以在机器学习算法中更好地处理离散特征，而不引入特定的顺序关系。我们以一个颜色特征为例来说明一下。假设我们有一个颜色特征，可能的取值有"红色"、"蓝色"和"绿色"。我们可以使用One-hot编码将这个颜色特征转化为二进制向量。
        "红色"可以表示为[1, 0, 0]
        "蓝色"可以表示为[0, 1, 0]
        "绿色"可以表示为[0, 0, 1]
        这样，我们就将原始的离散特征转化为了二进制向量，可以更好地在机器学习算法中进行处理。例如，在神经网络中，我们可以将这个特征作为输入向量的一部分，每个神经元对应一个特征取值，它们的激活状态表示该特征是否存在。

      </script>
	</div>


<div class="image">
	<div class="image-container">
			<figcaption>图片描述</figcaption>
			<img src="1.jpg" alt="图片1描述">
	</div>
	<div class="image-container">
			<figcaption>图片描述</figcaption>
			<img src="2.jpg" alt="图片2描述">
	</div>
    <div class="image-container">
            <figcaption>图片描述</figcaption>
            <img src="3.jpg" alt="图片3描述">
    </div>
    <div class="image-container">
            <figcaption>图片描述</figcaption>
            <img src="4.jpg" alt="图片4描述">
    </div>
        <div class="image-container">
            <figcaption>图片描述</figcaption>
            <img src="5.jpg" alt="图片5描述">
    </div>
    <div class="image-container">
            <figcaption>图片描述</figcaption>
            <img src="6.jpg" alt="图片6描述">
    </div>

</div>

  </body>
</html>